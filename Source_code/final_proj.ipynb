{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Please run pip install keras, and pip install tensoflow to use the libraries utilized in this code\n",
    "#Documentation to Keras API\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Input, LSTM\n",
    "from keras.layers import Bidirectional,Conv1D, GlobalMaxPool1D\n",
    "from keras import initializers, constraints, regularizers, optimizers, layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in data\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the head of data to take a peek\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up the variables\n",
    "categories=[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "y=train[categories].values\n",
    "train_set=train[\"comment_text\"]\n",
    "#Filling in empty fields\n",
    "train_set.fillna(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "maxfeatures = 25000\n",
    "maxlen=250\n",
    "dropout_rate=0.2\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "embed_d = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing sentences using the default tokenizer provided by kears\n",
    "tokenizer = Tokenizer(num_words=maxfeatures)\n",
    "tokenizer.fit_on_texts(list(train_set))\n",
    "tokenized_train = tokenizer.texts_to_sequences(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenized_train, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_seq = [len(seq) for seq in tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take a look at the average length of a sequence\n",
    "plt.hist(length_of_seq,bins = np.arange(0,500,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers: Embedding into bidirecitonal LSTM->Convousion 1 D->Max pooling->dropout->ReLu->dropout->sigmoid\n",
    "def lstm_cnn():\n",
    "    inputt = Input(shape=(maxlen, ))\n",
    "    x = Embedding(maxfeatures, embed_d)(inputt)\n",
    "    #https://keras.io/api/layers/recurrent_layers/bidirectional/\n",
    "    #https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "    x = Bidirectional(LSTM(60, return_sequences=True,name='lstm'))(x)\n",
    "    #https://keras.io/api/layers/convolution_layers/convolution1d/\n",
    "    x = Conv1D(64, 4,padding =\"valid\",kernel_initializer = \"glorot_uniform\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(60,activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(6,activation=\"sigmoid\")(x)\n",
    "    model=Model(inputt,x)\n",
    "    #https://keras.io/api/models/model_training_apis/#compile-method\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers: Embedding into LSTM ->Max pooling->dropout->ReLu->dropout->sigmoid\n",
    "def lstm():\n",
    "    inputt = Input(shape=(maxlen, ))\n",
    "    x = Embedding(maxfeatures, embed_d)(inputt)\n",
    "    #https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "    x = LSTM(60, return_sequences=True,name='lstm')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(60,activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(6,activation=\"sigmoid\")(x)\n",
    "    model=Model(inputt,x)\n",
    "    #https://keras.io/api/models/model_training_apis/#compile-method\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring the two models\n",
    "model1=lstm_cnn()\n",
    "model2=lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4488/4488 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9592\n",
      "Epoch 00001: val_loss improved from inf to 0.04924, saving model to best_weights_model1.hdf5\n",
      "4488/4488 [==============================] - 704s 157ms/step - loss: 0.0601 - accuracy: 0.9592 - val_loss: 0.0492 - val_accuracy: 0.9935\n",
      "Epoch 2/2\n",
      "4488/4488 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9760\n",
      "Epoch 00002: val_loss improved from 0.04924 to 0.04724, saving model to best_weights_model1.hdf5\n",
      "4488/4488 [==============================] - 674s 150ms/step - loss: 0.0423 - accuracy: 0.9760 - val_loss: 0.0472 - val_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "#Early stopping and training the first model (biLSTM-CNN)\n",
    "file_path1=\"best_weights_model1.hdf5\"\n",
    "chkpt1 = ModelCheckpoint(file_path1, 'val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early1 = EarlyStopping(\"val_loss\", mode=\"min\", patience=15)\n",
    "callbacks1 = [chkpt1, early1] \n",
    "#please note that validation split is similar to the train test split we used normally\n",
    "#so we save 10% of the data as validation data\n",
    "#https://keras.io/api/models/model_training_apis/#fit-method\n",
    "model1.fit(X_train, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks1)\n",
    "\n",
    "model1.load_weights(file_path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4488/4488 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9550\n",
      "Epoch 00001: val_loss improved from inf to 0.05058, saving model to best_weights_model2.hdf5\n",
      "4488/4488 [==============================] - 449s 100ms/step - loss: 0.0715 - accuracy: 0.9550 - val_loss: 0.0506 - val_accuracy: 0.9940\n",
      "Epoch 2/2\n",
      "4488/4488 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9884\n",
      "Epoch 00002: val_loss improved from 0.05058 to 0.04849, saving model to best_weights_model2.hdf5\n",
      "4488/4488 [==============================] - 457s 102ms/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.0485 - val_accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "#Early Stopping and training our second model (LSTM)\n",
    "file_path2=\"best_weights_model2.hdf5\"\n",
    "chkpt2 = ModelCheckpoint(file_path2,'val_loss',verbose=1, save_best_only=True, mode='min')\n",
    "early2 = EarlyStopping(\"val_loss\", mode=\"min\", patience=15)\n",
    "callbacks2 = [chkpt2, early2] \n",
    "#please note that validation split is similar to the train test split we used normally\n",
    "#so we save 10% of the data as validation data\n",
    "#https://keras.io/api/models/model_training_apis/#fit-method\n",
    "model2.fit(X_train, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks2)\n",
    "\n",
    "model2.load_weights(file_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 128)          3200000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 250, 120)          90720     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 247, 64)           30784     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                3900      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 366       \n",
      "=================================================================\n",
      "Total params: 3,325,770\n",
      "Trainable params: 3,325,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This summarizes the layers and the output dimensions of model1\n",
    "model1.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 250, 128)          3200000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 250, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 366       \n",
      "=================================================================\n",
      "Total params: 3,249,386\n",
      "Trainable params: 3,249,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This summarizes the layers and the output dimensions of model1\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
